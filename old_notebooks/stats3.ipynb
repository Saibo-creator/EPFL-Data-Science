{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the `SparkSession`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.90.38.21:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0.2.6.4.0-91</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>final_project-sciuto</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=final_project-sciuto>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = pyspark.conf.SparkConf()\n",
    "conf.setMaster('yarn')\n",
    "conf.setAppName('final_project-{0}'.format(getpass.getuser()))\n",
    "conf.set('spark.executor.memory', '12g')\n",
    "conf.set('spark.executor.instances', '12')\n",
    "conf.set('spark.executor.cores', '4')\n",
    "conf.set('spark.port.maxRetries', '200')\n",
    "#conf.set('files', 'file:///home/akozak/final_project/zurich_hb_stops.csv')\n",
    "sc = pyspark.SparkContext.getOrCreate(conf)\n",
    "conf = sc.getConf()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pyspark.sql.functions as functions\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = spark.read.csv(\"/datasets/project/istdaten/*/*/*.csv\", header=True, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rename some useful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BETRIEBSTAG', 'FAHRT_BEZEICHNER', 'BETREIBER_ID', 'BETREIBER_ABK', 'BETREIBER_NAME', 'PRODUKT_ID', 'LINIEN_ID', 'LINIEN_TEXT', 'UMLAUF_ID', 'VERKEHRSMITTEL_TEXT', 'ZUSATZFAHRT_TF', 'FAELLT_AUS_TF', 'BPUIC', 'HALTESTELLEN_NAME', 'ANKUNFTSZEIT', 'AN_PROGNOSE', 'AN_PROGNOSE_STATUS', 'ABFAHRTSZEIT', 'AB_PROGNOSE', 'AB_PROGNOSE_STATUS', 'DURCHFAHRT_TF']\n"
     ]
    }
   ],
   "source": [
    "oldColumns = whole_df.schema.names\n",
    "print(oldColumns)\n",
    "newColumns = [\"date\", 'trip_id', \n",
    "              'BETREIBER_ID', 'BETREIBER_ABK',\n",
    "              'BETREIBER_NAME', \"transport_type\", \n",
    "             \"train_line\", \"train_service\", \n",
    "              'UMLAUF_ID', 'VERKEHRSMITTEL_TEXT',\n",
    "             \"additional_trip\", \"failed_trip\",\n",
    "             'BPUIC', \"station_name\", \"arrival_time\",\n",
    "             \"actual_arrival\", 'AN_PROGNOSE_STATUS',\n",
    "             \"departure_time\", \"actual_departure\",\n",
    "             'AB_PROGNOSE_STATUS', \"DURCHFAHRT_TF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- trip_id: string (nullable = true)\n",
      " |-- BETREIBER_ID: string (nullable = true)\n",
      " |-- BETREIBER_ABK: string (nullable = true)\n",
      " |-- BETREIBER_NAME: string (nullable = true)\n",
      " |-- transport_type: string (nullable = true)\n",
      " |-- train_line: string (nullable = true)\n",
      " |-- train_service: string (nullable = true)\n",
      " |-- UMLAUF_ID: string (nullable = true)\n",
      " |-- VERKEHRSMITTEL_TEXT: string (nullable = true)\n",
      " |-- additional_trip: string (nullable = true)\n",
      " |-- failed_trip: string (nullable = true)\n",
      " |-- BPUIC: string (nullable = true)\n",
      " |-- station_name: string (nullable = true)\n",
      " |-- arrival_time: string (nullable = true)\n",
      " |-- actual_arrival: string (nullable = true)\n",
      " |-- AN_PROGNOSE_STATUS: string (nullable = true)\n",
      " |-- departure_time: string (nullable = true)\n",
      " |-- actual_departure: string (nullable = true)\n",
      " |-- AB_PROGNOSE_STATUS: string (nullable = true)\n",
      " |-- DURCHFAHRT_TF: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "whole_df = whole_df.toDF(*newColumns)\n",
    "whole_df.printSchema()\n",
    "# whole_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dropping useless columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = whole_df.drop('BETREIBER_ID','BETREIBER_ABK', 'BETREIBER_NAME', 'UMLAUF_ID', 'BPUIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load this csv having more than one executors it has to be put on HDFS\n",
    "radius_stations_df = spark.read.csv('/user/akozak/zurich_hb_stops.csv', header=True, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- elevation: string (nullable = true)\n",
      " |-- station_name: string (nullable = true)\n",
      " |-- dist_to_zurich_HB: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "radius_stations_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = whole_df.join(radius_stations_df, on=\"station_name\", how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIRD TABLE: COMPUTING THE DELTAS DELAYS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First assumptions: we filter entries were transport does not stop, entries that are additional trips and failed trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_table = filtered_df.filter((filtered_df.DURCHFAHRT_TF == False) \\\n",
    "                                 & (filtered_df.additional_trip == False)\\\n",
    "                                 & (filtered_df.failed_trip == False))#.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_trips = third_table.groupBy('trip_id').count().filter(\"count > 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_trips = useful_trips.drop('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- merging with our third table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_table = third_table.join(useful_trips, on=\"trip_id\", how='inner')#.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- look how distinct trip_id we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153572"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_table.select('trip_id').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- look trip_ids in the day we choose as regular day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_17_10_17 = third_table.filter(third_table.date == \"17.10.2017\").select('trip_id').distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- some checks with other days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_18_10_17 = third_table.filter(third_table.date == \"18.10.2017\").select('trip_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_14_10_17 = third_table.filter(third_table.date == \"14.10.2017\").select('trip_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_15_10_17 = third_table.filter(third_table.date == \"15.10.2017\").select('trip_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_05_03_18 = third_table.filter(third_table.date == \"05.03.2018\").select('trip_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_20_11_17 = third_table.filter(third_table.date == \"20.11.2017\").select('trip_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13892"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_14_10_17.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11092"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_15_10_17.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_trips = trips_17_10_17.join(trips_18_10_17, on=\"trip_id\", how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16657"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_trips.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19073"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_05_03_18.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8279"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_trips2 = trips_17_10_17.join(trips_05_03_18, on=\"trip_id\", how='inner')\n",
    "join_trips2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withColumn('arrival_delay', when((third_table.actual_arrival.isNull()) \\\n",
    "                                  & (third_table.arrival_time.isNull()), None\n",
    "                                 )\n",
    "                                 .when((third_table.actual_arrival.isNull()) \\\n",
    "                                       & (third_table.arrival_time.isNotNull()), 0)\\\n",
    "                                 .otherwise(functions.round(unix_timestamp(\"actual_arrival\",'dd.MM.yyyy HH:mm') - \\\n",
    "                                            unix_timestamp(\"arrival_time\",'dd.MM.yyyy HH:mm')) / 60))\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|       trip_id|\n",
      "+--------------+\n",
      "|  85:11:10:002|\n",
      "|  85:11:11:004|\n",
      "|85:11:1251:001|\n",
      "|85:11:1255:001|\n",
      "|85:11:1256:002|\n",
      "|85:11:1258:001|\n",
      "|85:11:1260:001|\n",
      "|  85:11:12:002|\n",
      "|  85:11:13:006|\n",
      "|85:11:1408:002|\n",
      "|85:11:1410:001|\n",
      "|85:11:1411:001|\n",
      "|85:11:1429:001|\n",
      "|85:11:1431:001|\n",
      "|  85:11:14:003|\n",
      "|85:11:1507:002|\n",
      "|85:11:1508:002|\n",
      "|85:11:1509:002|\n",
      "|85:11:1510:002|\n",
      "|85:11:1511:002|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_17_10_17 = trips_17_10_17.orderBy('trip_id')\n",
    "trips_17_10_17.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|       trip_id|\n",
      "+--------------+\n",
      "|  85:11:10:002|\n",
      "|  85:11:11:001|\n",
      "|85:11:1251:001|\n",
      "|85:11:1252:001|\n",
      "|85:11:1255:001|\n",
      "|85:11:1256:003|\n",
      "|85:11:1260:001|\n",
      "|  85:11:12:001|\n",
      "|  85:11:13:001|\n",
      "|85:11:1408:001|\n",
      "|85:11:1410:002|\n",
      "|85:11:1411:001|\n",
      "|85:11:1429:001|\n",
      "|85:11:1431:001|\n",
      "|85:11:1456:001|\n",
      "|85:11:1458:001|\n",
      "|85:11:1463:001|\n",
      "|85:11:1489:001|\n",
      "|  85:11:14:001|\n",
      "|85:11:1507:002|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_05_03_18 = trips_05_03_18.orderBy('trip_id')\n",
    "trips_05_03_18.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = trips_17_10_17.withColumn('different_trip_id', when(trips_17_10_17.trip_id.isin(trips_05_03_18.trip_id), None )\\\n",
    "                                   .otherwise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1674"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_trips3 = trips_17_10_17.join(trips_15_10_17, on=\"trip_id\", how='inner')\n",
    "join_trips3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14846"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_trips4 = trips_17_10_17.join(trips_20_11_17, on=\"trip_id\", how='inner')\n",
    "join_trips4.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_20_12_17 = third_table.filter(third_table.date == \"20.12.2017\").select('trip_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16209"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_20_12_17.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8556"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_trips5 = trips_17_10_17.join(trips_20_12_17, on=\"trip_id\", how='inner')\n",
    "join_trips5.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_29_01_18 = third_table.filter(third_table.date == \"29.01.2018\").select('trip_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16221"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_29_01_18.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8009"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_trips5 = trips_17_10_17.join(trips_29_01_18, on=\"trip_id\", how='inner')\n",
    "join_trips5.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if we just use only the GESCHAETZT entries, we will use only 4.8 % of our available data. Also, if we drop all the other entries there is the risk to lose information about some connection in our network. Right now we will just compute the difference of the columns. A further discussion with the other group members and TAs should be done.\n",
    "- Is critical how to handle the null values, do we put delay = 0 if null? Or do we drop those entries? (by dropping them, we stil have the same problem highlighted in the first point of this cell. Right now I put a zero for all the null values.\n",
    "- We also create a 'hour' column because it could be useful for the statitistics tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when,unix_timestamp,hour,to_timestamp,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_table_final = third_table\\\n",
    ".withColumn('arrival_delay', when((third_table.actual_arrival.isNull()) \\\n",
    "                                  & (third_table.arrival_time.isNull()), None\n",
    "                                 )\n",
    "                                 .when((third_table.actual_arrival.isNull()) \\\n",
    "                                       & (third_table.arrival_time.isNotNull()), 0)\\\n",
    "                                 .otherwise(functions.round(unix_timestamp(\"actual_arrival\",'dd.MM.yyyy HH:mm') - \\\n",
    "                                            unix_timestamp(\"arrival_time\",'dd.MM.yyyy HH:mm')) / 60))\\\n",
    "\n",
    ".withColumn('departure_delay', when((third_table.actual_departure.isNull())\\\n",
    "                                    & (third_table.departure_time.isNull()), None\n",
    "                                 )\n",
    "                                 .when((third_table.actual_departure.isNull()) \\\n",
    "                                       & (third_table.departure_time.isNotNull()), 0)\\\n",
    "                                    .otherwise(functions.round(unix_timestamp(\"actual_departure\",'dd.MM.yyyy HH:mm')\\\n",
    "                                               - unix_timestamp(\"departure_time\",'dd.MM.yyyy HH:mm')) /60))\\\n",
    ".withColumn('hour',  when(third_table.arrival_time.isNull(), hour(to_timestamp(third_table.departure_time,\n",
    "                                                                              'dd.MM.yyyy HH:mm'))) \\\n",
    "                         .otherwise(hour(to_timestamp(third_table.arrival_time, 'dd.MM.yyyy HH:mm'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STATISTICS TETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section we will produce statistics tests in order to see if our bins delays can fit well a known distribution (we were thinking about a logNormal distr).\n",
    "- First we will produce the test on the whole dataset, that means on the third table.\n",
    "- then we will run a test on the delays on each station (group by station name)\n",
    "- after this we will do the same for each transport line (group by the line_id, right now the columns is erroneusly called 'train_line')\n",
    "- then, the same thing for each trip (group by trip_id)\n",
    "- finally, same tests for hour of the day (we need to choose how to split the day, right now the column 'hour' has 24 distinct values of course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import lognorm\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from scipy.stats import lognorm\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trip_id',\n",
       " 'station_name',\n",
       " 'date',\n",
       " 'transport_type',\n",
       " 'train_line',\n",
       " 'train_service',\n",
       " 'VERKEHRSMITTEL_TEXT',\n",
       " 'additional_trip',\n",
       " 'failed_trip',\n",
       " 'arrival_time',\n",
       " 'actual_arrival',\n",
       " 'AN_PROGNOSE_STATUS',\n",
       " 'departure_time',\n",
       " 'actual_departure',\n",
       " 'AB_PROGNOSE_STATUS',\n",
       " 'DURCHFAHRT_TF',\n",
       " 'id',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'elevation',\n",
       " 'dist_to_zurich_HB',\n",
       " 'arrival_delay',\n",
       " 'departure_delay',\n",
       " 'hour']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_table_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51046552"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_table_final.cache().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_table_final_dep=third_table_final.where(col(\"departure_delay\").isNotNull())\n",
    "third_table_final_arr=third_table_final.where(col(\"arrival_delay\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay_dep = third_table_final_dep.groupBy('trip_id','station_name').agg(functions.collect_list(\"departure_delay\").alias('list_dep_delay'))\n",
    "df_delay_arr = third_table_final_arr.groupBy('trip_id','station_name').agg(functions.collect_list(\"arrival_delay\").alias('list_arr_delay'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2271318"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_delay_arr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay_dep_param=df_delay_dep.rdd.map(lambda x:[x['trip_id'], x['station_name'],[float(b) for b in lognorm.fit(x['list_dep_delay'])]])\n",
    "df_delay_arr_param=df_delay_arr.rdd.map(lambda x:[x['trip_id'], x['station_name'],[float(b) for b in lognorm.fit(x['list_arr_delay'])]])\n",
    "\n",
    "\n",
    "df_delay_dep_fit=df_delay_dep_param.map(lambda x:(x[0],x[1],x[2])).toDF(['trip_id','station_name','fit_param_dep'])\n",
    "df_delay_arr_fit=df_delay_arr_param.map(lambda x:(x[0],x[1],x[2])).toDF(['trip_id','station_name','fit_param_arr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+--------------------+\n",
      "|        trip_id|       station_name|       fit_param_arr|\n",
      "+---------------+-------------------+--------------------+\n",
      "|85:11:13752:001|     Birmensdorf ZH|[0.64744702021595...|\n",
      "|85:11:13752:001|Bonstetten-Wettswil|[0.64971286678057...|\n",
      "+---------------+-------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_delay_arr_fit.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+--------------------+\n",
      "|        trip_id|       station_name|       fit_param_dep|\n",
      "+---------------+-------------------+--------------------+\n",
      "|85:11:13752:001|     Birmensdorf ZH|[0.64242304975669...|\n",
      "|85:11:13752:001|Bonstetten-Wettswil|[0.46106848938145...|\n",
      "+---------------+-------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_delay_dep_fit.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the parameters in 3 columns :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay_dep_param_split=df_delay_dep_fit.select('trip_id','station_name',df_delay_dep_fit[\"fit_param_dep\"].getItem(0).alias(\"shape_dep\"),df_delay_dep_fit[\"fit_param_dep\"].getItem(1).alias(\"mean_dep\"),df_delay_dep_fit[\"fit_param_dep\"].getItem(2).alias(\"std_dep\"))\n",
    "df_delay_arr_param_split=df_delay_arr_fit.select('trip_id','station_name',df_delay_arr_fit[\"fit_param_arr\"].getItem(0).alias(\"shape_arr\"),df_delay_arr_fit[\"fit_param_arr\"].getItem(1).alias(\"mean_arr\"),df_delay_arr_fit[\"fit_param_arr\"].getItem(2).alias(\"std_arr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay_dep_param_split_pandas = df_delay_dep_param_split.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>shape_dep</th>\n",
       "      <th>mean_dep</th>\n",
       "      <th>std_dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Birmensdorf ZH</td>\n",
       "      <td>0.647447</td>\n",
       "      <td>-1.649415</td>\n",
       "      <td>2.571467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Bonstetten-Wettswil</td>\n",
       "      <td>0.649713</td>\n",
       "      <td>-0.743932</td>\n",
       "      <td>2.739554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Urdorf</td>\n",
       "      <td>0.691869</td>\n",
       "      <td>-0.505328</td>\n",
       "      <td>2.098195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Urdorf Weihermatt</td>\n",
       "      <td>0.663387</td>\n",
       "      <td>0.483230</td>\n",
       "      <td>2.317448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Zürich Altstetten</td>\n",
       "      <td>0.755722</td>\n",
       "      <td>0.541231</td>\n",
       "      <td>1.650423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           trip_id         station_name  shape_dep  mean_dep   std_dep\n",
       "0  85:11:13752:001       Birmensdorf ZH   0.647447 -1.649415  2.571467\n",
       "1  85:11:13752:001  Bonstetten-Wettswil   0.649713 -0.743932  2.739554\n",
       "2  85:11:13752:001               Urdorf   0.691869 -0.505328  2.098195\n",
       "3  85:11:13752:001    Urdorf Weihermatt   0.663387  0.483230  2.317448\n",
       "4  85:11:13752:001    Zürich Altstetten   0.755722  0.541231  1.650423"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_delay_dep_param_split_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay_dep_param_split_pandas.to_csv(\"delay_dep_param.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay_arr_param_split_pandas = df_delay_arr_param_split.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay_arr_param_split_pandas.to_csv('delay_arr_param.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>shape_arr</th>\n",
       "      <th>mean_arr</th>\n",
       "      <th>std_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Birmensdorf ZH</td>\n",
       "      <td>0.647447</td>\n",
       "      <td>-1.649415</td>\n",
       "      <td>2.571467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Bonstetten-Wettswil</td>\n",
       "      <td>0.649713</td>\n",
       "      <td>-0.743932</td>\n",
       "      <td>2.739554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Urdorf</td>\n",
       "      <td>0.691869</td>\n",
       "      <td>-0.505328</td>\n",
       "      <td>2.098195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Urdorf Weihermatt</td>\n",
       "      <td>0.663387</td>\n",
       "      <td>0.483230</td>\n",
       "      <td>2.317448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Zürich Altstetten</td>\n",
       "      <td>0.755722</td>\n",
       "      <td>0.541231</td>\n",
       "      <td>1.650423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           trip_id         station_name  shape_arr  mean_arr   std_arr\n",
       "0  85:11:13752:001       Birmensdorf ZH   0.647447 -1.649415  2.571467\n",
       "1  85:11:13752:001  Bonstetten-Wettswil   0.649713 -0.743932  2.739554\n",
       "2  85:11:13752:001               Urdorf   0.691869 -0.505328  2.098195\n",
       "3  85:11:13752:001    Urdorf Weihermatt   0.663387  0.483230  2.317448\n",
       "4  85:11:13752:001    Zürich Altstetten   0.755722  0.541231  1.650423"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_delay_arr_param_split_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_params = pd.merge(df_delay_dep_param_split_pandas, df_delay_arr_param_split_pandas, on=['trip_id', 'station_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_params.to_csv(\"delay_params.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>shape_dep</th>\n",
       "      <th>mean_dep</th>\n",
       "      <th>std_dep</th>\n",
       "      <th>shape_arr</th>\n",
       "      <th>mean_arr</th>\n",
       "      <th>std_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Birmensdorf ZH</td>\n",
       "      <td>0.642423</td>\n",
       "      <td>-0.715683</td>\n",
       "      <td>2.617516</td>\n",
       "      <td>0.647447</td>\n",
       "      <td>-1.649415</td>\n",
       "      <td>2.571467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Bonstetten-Wettswil</td>\n",
       "      <td>0.461068</td>\n",
       "      <td>-1.201161</td>\n",
       "      <td>4.136449</td>\n",
       "      <td>0.649713</td>\n",
       "      <td>-0.743932</td>\n",
       "      <td>2.739554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Urdorf</td>\n",
       "      <td>0.511910</td>\n",
       "      <td>-0.678884</td>\n",
       "      <td>3.233112</td>\n",
       "      <td>0.691869</td>\n",
       "      <td>-0.505328</td>\n",
       "      <td>2.098195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Urdorf Weihermatt</td>\n",
       "      <td>0.485538</td>\n",
       "      <td>0.206669</td>\n",
       "      <td>3.601493</td>\n",
       "      <td>0.663387</td>\n",
       "      <td>0.483230</td>\n",
       "      <td>2.317448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85:11:13752:001</td>\n",
       "      <td>Zürich Altstetten</td>\n",
       "      <td>0.586274</td>\n",
       "      <td>0.380187</td>\n",
       "      <td>2.598591</td>\n",
       "      <td>0.755722</td>\n",
       "      <td>0.541231</td>\n",
       "      <td>1.650423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           trip_id         station_name  shape_dep  mean_dep   std_dep  \\\n",
       "0  85:11:13752:001       Birmensdorf ZH   0.642423 -0.715683  2.617516   \n",
       "1  85:11:13752:001  Bonstetten-Wettswil   0.461068 -1.201161  4.136449   \n",
       "2  85:11:13752:001               Urdorf   0.511910 -0.678884  3.233112   \n",
       "3  85:11:13752:001    Urdorf Weihermatt   0.485538  0.206669  3.601493   \n",
       "4  85:11:13752:001    Zürich Altstetten   0.586274  0.380187  2.598591   \n",
       "\n",
       "   shape_arr  mean_arr   std_arr  \n",
       "0   0.647447 -1.649415  2.571467  \n",
       "1   0.649713 -0.743932  2.739554  \n",
       "2   0.691869 -0.505328  2.098195  \n",
       "3   0.663387  0.483230  2.317448  \n",
       "4   0.755722  0.541231  1.650423  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_params.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=delay_params.groupby(['trip_id', 'station_name'],as_index=False)['shape_dep', 'mean_dep', 'std_dep',\n",
    "       'shape_arr', 'mean_arr', 'std_arr'].apply(lambda x : x.values.tolist()[0]).to_frame()\n",
    "\n",
    "def recur_dictify(frame):\n",
    "    if len(frame.columns) == 1:\n",
    "        if frame.values.size == 1: return frame.values[0][0]\n",
    "        return frame.values.squeeze()\n",
    "    grouped = frame.groupby(frame.columns[0])\n",
    "    d = {k: recur_dictify(g.iloc[:,1:]) for k,g in grouped}\n",
    "    return d\n",
    "\n",
    "\n",
    "delays_dict = recur_dictify(dd.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Birmensdorf ZH': [0.6424230497566921,\n",
       "  -0.7156830945161855,\n",
       "  2.6175157868578487,\n",
       "  0.6474470202159504,\n",
       "  -1.6494151038426064,\n",
       "  2.5714673710314537],\n",
       " 'Bonstetten-Wettswil': [0.4610684893814535,\n",
       "  -1.2011608867353814,\n",
       "  4.136448664880946,\n",
       "  0.6497128667805727,\n",
       "  -0.7439320429616096,\n",
       "  2.7395542606923],\n",
       " 'Urdorf': [0.5119096382336292,\n",
       "  -0.6788836778776737,\n",
       "  3.233111640184454,\n",
       "  0.6918689182829518,\n",
       "  -0.5053278033593314,\n",
       "  2.0981950381446564],\n",
       " 'Urdorf Weihermatt': [0.48553771228888437,\n",
       "  0.20666937426606913,\n",
       "  3.6014926573494055,\n",
       "  0.6633866660825061,\n",
       "  0.48322999401788624,\n",
       "  2.3174484760115375],\n",
       " 'Zürich Altstetten': [0.5862735581954911,\n",
       "  0.380187219532638,\n",
       "  2.5985910526787928,\n",
       "  0.7557217285665694,\n",
       "  0.541231305636209,\n",
       "  1.650422933206059],\n",
       " 'Zürich HB': [1.7133024431228892,\n",
       "  -1.2209669461901277e-05,\n",
       "  0.00022974235779182949,\n",
       "  22.64985321953943,\n",
       "  -1.0000000000000027,\n",
       "  0.004666414825163004],\n",
       " 'Zürich Hardbrücke': [0.7783684665489181,\n",
       "  -0.13950422133332674,\n",
       "  1.870830380256868,\n",
       "  7.142022833654211,\n",
       "  -6.315720990908571e-19,\n",
       "  5.583296788364906e-05],\n",
       " 'Zürich Stadelhofen': [3.3736493045684504,\n",
       "  -6.781505065377167e-14,\n",
       "  5.954587552050018e-09,\n",
       "  0.6843925375220552,\n",
       "  -2.4835761065060367,\n",
       "  1.3204063616856043]}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delays_dict['85:11:13752:001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(delays_dict, open( \"delays_dict.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
